{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from iit import get_equality_dataset, get_IIT_equality_dataset, get_IIT_equality_dataset_both\n",
    "from torch_deep_neural_classifier_iit import TorchDeepNeuralClassifierIIT, TorchDeepNeuralClassifier\n",
    "from torch_rnn_classifier import TorchRNNClassifier\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Hierarchical Equality Dataset](#Hierarchical-Equality-Dataset)\n",
    "2. [High-Level Tree-Structured Algorithm](#The-High-Level-Tree-Structured-Algorithm)\n",
    "3. [A Fully-Connected Feed-Forward Neural Network](#A-Fully-Connected-Feed-Forward-Neural-Network)\n",
    "4. [Causal Abstraction](#Causal-Abstraction)\n",
    "5. [Interchange Intervention Training (IIT)](#Interchange-Intervention-Training-(IIT))\n",
    "\n",
    "## Hierarchical Equality Dataset  \n",
    "[Geiger, Carstensen, Frank, and Potts (2020)](https://arxiv.org/abs/2006.07968)\n",
    "\n",
    "We will use a hierarchical equality task to present IIT. We define the hierarchical equality task as follows: The input is two pairs of objects and the output is **true** if both pairs contain the same object or if both pairs contain different objects and **false** otherwise. For example, AABB and ABCD are both labeled **true** while ABCC and BBCD are both labeled **false**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The High-Level Tree-Structured Algorithm\n",
    "\n",
    "Let $\\mathcal{A}$ be the simple tree structured algorithm that solves this task by applying a simple equality relation three times: Compute whether the first two inputs are equal, compute whether the second two inputs are equal, then compute whether\n",
    "the truth-valued outputs of these first two computations are equal. We visually define $\\mathcal{A}$ below and then define a python function that computes $\\mathcal{A}$, possibly under an intervention that sets $V_1$ and/or $V_2$ to fixed values.\n",
    "\n",
    "<img src=\"fig/IIT/PremackFunctions.png\" width=\"500\"/>\n",
    "<img src=\"fig/IIT/PremackGraph.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_A(input, intervention):\n",
    "    graph = dict()\n",
    "    for i, object in enumerate(input):\n",
    "        graph[\"input\" + str(i+1)] = object\n",
    "    if \"V1\" in intervention:\n",
    "        graph[\"V1\"] = intervention[\"V1\"]\n",
    "    else:\n",
    "        graph[\"V1\"] = graph[\"input1\"] == graph[\"input2\"]\n",
    "    if \"V2\" in intervention:\n",
    "        graph[\"V2\"] = intervention[\"V2\"]\n",
    "    else:\n",
    "        graph[\"V2\"] = graph[\"input3\"] == graph[\"input4\"]\n",
    "    graph[\"output\"] = graph[\"V1\"] == graph[\"V2\"]\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm with no intervention\n",
    "\n",
    "First, observe the behavior of the algorithm whhen we provide the input **(pentagon,pentagon, triangle, square)** with no intervention. We show this visually and by using our **compute_A** function.\n",
    "\n",
    "<img src=\"fig/IIT/PremackNoIntervention.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input1': 'pentagon',\n",
       " 'input2': 'pentagon',\n",
       " 'input3': 'triangle',\n",
       " 'input4': 'square',\n",
       " 'V1': True,\n",
       " 'V2': False,\n",
       " 'output': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_A((\"pentagon\", \"pentagon\", \"triangle\", \"square\"), {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm with an intervention\n",
    "\n",
    "Observe the behavior of the algorithm whhen we provide the input **(square,pentagon, triangle, triangle)** with an intervention setting **V1** to **False**. We show this visually and by using our **compute_A** function.\n",
    "\n",
    "<img src=\"fig/IIT/PremackIntervention.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input1': 'square',\n",
       " 'input2': 'pentagon',\n",
       " 'input3': 'triangle',\n",
       " 'input4': 'triangle',\n",
       " 'V1': True,\n",
       " 'V2': True,\n",
       " 'output': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_A((\"square\", \"pentagon\", \"triangle\", \"triangle\"), {\"V1\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm with an interchange intervention\n",
    "\n",
    "Finaally, observe the behavior of the algorithm when we provide the base input **(square,pentagon, triangle, triangle)** with an intervention setting **V1** to be the value it would be for the source input **(pentagon,pentagon, triangle, square)**. We show this visually and by using our **compute_A** function.\n",
    "\n",
    "<img src=\"fig/IIT/algorithmII.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input1': 'pentagon',\n",
       " 'input2': 'pentagon',\n",
       " 'input3': 'triangle',\n",
       " 'input4': 'square',\n",
       " 'V1': False,\n",
       " 'V2': False,\n",
       " 'output': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seems like this interchange is working the other way around? (swapping V1 from right to left)\n",
    "\n",
    "def compute_interchange_A(base,source, variable):\n",
    "    return compute_A(base, {variable:compute_A(source, {})[variable]})\n",
    "    \n",
    "compute_interchange_A((\"pentagon\", \"pentagon\", \"triangle\", \"square\"), (\"square\", \"pentagon\", \"triangle\", \"triangle\"), \"V1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Fully-Connected Feed-Forward Neural Network\n",
    "\n",
    "We will train a three layer feed-forward neural network on this task where each object has a random vector assigned to it and the objects in training are disjoint from the objects seen in testing.\n",
    "\n",
    "<img src=\"fig/IIT/Network.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterventionableTorchDeepNeuralClassifier(TorchDeepNeuralClassifier):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def make_hook(self, gets, sets, layer):\n",
    "        # a hook is some lambda function that manipulates the internal state of the model?\n",
    "        def hook(model, input, output):\n",
    "            layer_gets, layer_sets = [], []\n",
    "            if gets is not None and layer in gets:\n",
    "                layer_gets = gets[layer]\n",
    "            if sets is not None and layer in sets:\n",
    "                layer_sets = sets[layer]\n",
    "            # get commands retrieve values from a computed hidden layer\n",
    "            for get in layer_gets:\n",
    "                self.activation[f'{get[\"layer\"]}-{get[\"start\"]}-{get[\"end\"]}'] = output[:,get[\"start\"]: get[\"end\"] ]\n",
    "            # set commands fix values of a hidden layer\n",
    "            # do these changes propagate?\n",
    "            for set in layer_sets:\n",
    "                output[:,set[\"start\"]: set[\"end\"]] = set[\"intervention\"]\n",
    "        return hook\n",
    "\n",
    "    def _gets_sets(self,gets=None, sets = None):\n",
    "        handlers = []\n",
    "        for layer in range(len(self.layers)):\n",
    "            hook = self.make_hook(gets,sets, layer)\n",
    "            # what does it mean to register a forward hook? is a hook similar to a replacement/intervention\n",
    "            # on a hidden layer?\n",
    "            both_handler = self.layers[layer].register_forward_hook(hook)\n",
    "            handlers.append(both_handler)\n",
    "        return handlers\n",
    "\n",
    "    # overwrites/fetches hidden layer for neural network?\n",
    "    def retrieve_activations(self, input, get, sets):\n",
    "        input = input.type(torch.FloatTensor).to(self.device)\n",
    "        self.activation = dict()\n",
    "        handlers = self._gets_sets({get[\"layer\"]:[get]}, sets)\n",
    "        logits = self.model(input) # what do we use the logits for? are we running our model through all layers?\n",
    "        for handler in handlers:\n",
    "            handler.remove()\n",
    "        return self.activation[f'{get[\"layer\"]}-{get[\"start\"]}-{get[\"end\"]}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 649. Training loss did not improve more than tol=1e-05. Final error is 0.00046398123049584683."
     ]
    }
   ],
   "source": [
    "\n",
    "TRUE_LABEL = 1\n",
    "FALSE_LABEL = 0\n",
    "\n",
    "data_size = 1024 * 10\n",
    "embedding_dim = 4\n",
    "X_train, X_test, y_train, y_test, test_dataset = get_equality_dataset(embedding_dim,10000)\n",
    "\n",
    "model = InterventionableTorchDeepNeuralClassifier(hidden_dim=4*embedding_dim, hidden_activation=torch.nn.ReLU(), num_layers=3)\n",
    "_ = model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that this neural network achieves near perfect performance on its test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4365, -0.0289, -0.2255,  0.3735,  0.4365, -0.0289, -0.2255,  0.3735,\n",
      "         0.3634,  0.1236,  0.0243, -0.1352,  0.4411, -0.2673, -0.4682, -0.3980],\n",
      "       dtype=torch.float64) 0\n",
      "Train Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Test Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# double-checking: top example seems to be {A, A}, {B, C}? \n",
    "# (this can change depending on the order of the cells being run)\n",
    "print(X_train[0], y_train[0])\n",
    "preds = model.predict(X_train)\n",
    "print(\"Train Results\")\n",
    "print(classification_report(y_train, preds))\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# i see near-perfect performance on the training set, but the performance on the test set doesn't look all that good...\n",
    "# given the comment above, is this expected?\n",
    "print(\"\\n\\n\\nTest Results\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The network with no intervention\n",
    "\n",
    "First, observe the behavior of the network when we provide the input **(pentagon,pentagon, triangle, square)** with no intervention. We assign each shape a random vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[-0.027239528153731096, -0.1708941925356774, 0.10471252264638642, -0.03486029578210181, -0.027239528153731096, -0.1708941925356774, 0.10471252264638642, -0.03486029578210181, 0.42314000042542865, -0.44822583072577604, 0.3215207354592715, 0.35969762210932066, 0.23637433807549235, 0.4279018218631253, -0.0706330407827378, 0.3186659056305904]]\n",
      "\n",
      "Layer 0: ActivationLayer(\n",
      "  (linear): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[1.3238e-01, 1.0843e-01, 0.0000e+00, 1.7661e-01, 5.6381e-01, 0.0000e+00,\n",
      "         4.7403e-01, 4.4808e-03, 3.3821e-01, 2.9191e-02, 2.3711e-05, 0.0000e+00,\n",
      "         0.0000e+00, 1.0986e-03, 0.0000e+00, 5.7847e-01]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 1: ActivationLayer(\n",
      "  (linear): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[0.0000, 0.6655, 0.3471, 0.5689, 1.0628, 0.6814, 0.0835, 0.4683, 0.0000,\n",
      "         0.4746, 0.4940, 0.0000, 0.0000, 0.6480, 0.6503, 0.0000]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 2: ActivationLayer(\n",
      "  (linear): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[0.8386, 2.2602, 0.6748, 0.9887, 0.0000, 1.0327, 0.0000, 0.0000, 0.3059,\n",
      "         0.0773, 0.0000, 0.9729, 0.9372, 1.0647, 0.3992, 2.2476]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 3: Linear(in_features=16, out_features=2, bias=True)\n",
      "\n",
      "Neural Activations: tensor([[ 6.2727, -6.4216]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "pentagon = [random.uniform(-0.5,0.5) for _ in range(embedding_dim)]\n",
    "triangle = [random.uniform(-0.5,0.5) for _ in range(embedding_dim)]\n",
    "square = [random.uniform(-0.5,0.5) for _ in range(embedding_dim)]\n",
    "\n",
    "# how can I tell the final prediction from the neural activations?\n",
    "\n",
    "print(\"Input:\",[[*pentagon,*pentagon,*triangle,*square]])\n",
    "for k in range(len(model.layers)):\n",
    "    # build a get request for which layer and which values we want to see\n",
    "    get_coord = {\"layer\":k, \"start\":0, \"end\":embedding_dim*4}\n",
    "    print(f\"\\nLayer {k}:\", model.layers[k])\n",
    "    # prints actual hidden values (activations) of the neural network layer\n",
    "    print(\"\\nNeural Activations:\", model.retrieve_activations(torch.tensor([[*pentagon,*pentagon,*triangle,*square]]), get_coord, None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The network with an intervention\n",
    "\n",
    "Now, observe the behavior of the network when we provide the input **(pentagon,pentagon, triangle, square)** with an intervention that zeros out five neurons after the first hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[-0.027239528153731096, -0.1708941925356774, 0.10471252264638642, -0.03486029578210181, -0.027239528153731096, -0.1708941925356774, 0.10471252264638642, -0.03486029578210181, 0.42314000042542865, -0.44822583072577604, 0.3215207354592715, 0.35969762210932066, 0.23637433807549235, 0.4279018218631253, -0.0706330407827378, 0.3186659056305904]]\n",
      "\n",
      "Layer 0: ActivationLayer(\n",
      "  (linear): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[1.3238e-01, 1.0843e-01, 0.0000e+00, 1.7661e-01, 5.6381e-01, 0.0000e+00,\n",
      "         4.7403e-01, 4.4808e-03, 3.3821e-01, 2.9191e-02, 2.3711e-05, 0.0000e+00,\n",
      "         0.0000e+00, 1.0986e-03, 0.0000e+00, 5.7847e-01]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 1: ActivationLayer(\n",
      "  (linear): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[0.0000, 0.6655, 0.3471, 0.5689, 1.0628, 0.6814, 0.0835, 0.4683, 0.0000,\n",
      "         0.4746, 0.4940, 0.0000, 0.0000, 0.6480, 0.6503, 0.0000]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 2: ActivationLayer(\n",
      "  (linear): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[0.8386, 2.2602, 0.6748, 0.9887, 0.0000, 1.0327, 0.0000, 0.0000, 0.3059,\n",
      "         0.0773, 0.0000, 0.9729, 0.9372, 1.0647, 0.3992, 2.2476]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 3: Linear(in_features=16, out_features=2, bias=True)\n",
      "\n",
      "Neural Activations: tensor([[ 6.2727, -6.4216]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "# command to actually change the value of the first layer\n",
    "# does this change the computations of the following layers? Oh! Is this why we re-compute the model (from start\n",
    "# to finish) each time we call retreive_activations()?\n",
    "set_coord = {\"layer\":1, \"start\":0, \"end\":embedding_dim, \"intervention\": torch.tensor([[0 for _ in range(embedding_dim)]])}\n",
    "\n",
    "print(\"Input:\",[[*pentagon,*pentagon,*triangle,*square]])\n",
    "for k in range(len(model.layers)):\n",
    "    get_coord = {\"layer\":k, \"start\":0, \"end\":embedding_dim*4}\n",
    "    print(f\"\\nLayer {k}:\", model.layers[k])\n",
    "    # we pass in the set request every call, but this will really only apply to layer 1\n",
    "    print(\"\\nNeural Activations:\", model.retrieve_activations(torch.tensor([[*pentagon,*pentagon,*triangle,*square]]), get_coord, set_coord))\n",
    "\n",
    "# where should I see the 0's pop up?\n",
    "# this intervention didn't change the output of the model (but I imagine this is expected?)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The network with an interchange intervention\n",
    "\n",
    "Finally, observe the behavior of the network when we provide the input **(square, pentagon, triangle, triangle)** with an intervention that sets five neurons after the first hidden layer to the values they achieve for the source input **(pentagon,pentagon, triangle, square)**.\n",
    "<img src=\"fig/IIT/networkII.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[-0.027239528153731096, -0.1708941925356774, 0.10471252264638642, -0.03486029578210181, -0.027239528153731096, -0.1708941925356774, 0.10471252264638642, -0.03486029578210181, 0.42314000042542865, -0.44822583072577604, 0.3215207354592715, 0.35969762210932066, 0.23637433807549235, 0.4279018218631253, -0.0706330407827378, 0.3186659056305904]]\n",
      "\n",
      "Layer 0: ActivationLayer(\n",
      "  (linear): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[0.5472, 0.0215, 0.0000, 0.1866, 0.5763, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2921, 0.4541, 0.2680, 0.0000, 0.6818, 0.0050, 0.0000]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 1: ActivationLayer(\n",
      "  (linear): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[1.3066, 0.6663, 0.0000, 0.8273, 0.3432, 0.7402, 0.7459, 0.0000, 1.0878,\n",
      "         0.0000, 0.0000, 0.0000, 0.5465, 0.0489, 0.3966, 0.3415]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 2: ActivationLayer(\n",
      "  (linear): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[0.8841, 0.0000, 0.4940, 0.6338, 2.3123, 0.8758, 0.0000, 0.0000, 0.7318,\n",
      "         1.3956, 2.1877, 0.6168, 0.7690, 0.9285, 0.9532, 0.0000]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 3: Linear(in_features=16, out_features=2, bias=True)\n",
      "\n",
      "Neural Activations: tensor([[ 8.0475, -8.4772]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "# this time our set command depends upon a separate input (in this case, {P, P}, {T, S})\n",
    "intervention = model.retrieve_activations(torch.tensor([[*pentagon,*pentagon,*triangle,*square]]), {\"layer\":1, \"start\":0, \"end\":embedding_dim},None)\n",
    "\n",
    "set_coord = {\"layer\":1, \"start\":0, \"end\":embedding_dim, \"intervention\": intervention}\n",
    "\n",
    "print(\"Input:\",[[*pentagon,*pentagon,*triangle,*square]])\n",
    "for k in range(len(model.layers)):\n",
    "    get_coord = {\"layer\":k, \"start\":0, \"end\":embedding_dim*4}\n",
    "    print(f\"\\nLayer {k}:\", model.layers[k])\n",
    "    print(\"\\nNeural Activations:\", model.retrieve_activations(torch.tensor([[*square,*pentagon,*triangle,*triangle]]), get_coord, set_coord))\n",
    "\n",
    "# how can I tell whether this changed the final output? (how is the final output, T/F, calculated?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Abstraction\n",
    "\n",
    "We defined a **high-level tree structured agorithm** that solves the hierarchical equality task.\n",
    "\n",
    "We trained a **low-level fully connected neural network** that solves the hierarchical equality task.\n",
    "\n",
    "A formal theory of **causal abstraction** describes the conditions that must hold for the high-level tree structured algorithm to be a **simplified and faithful description** of the neural network: \n",
    "\n",
    "**An algorithm is a causal abstraction of a neural network if and only if for all base and source inputs, the algorithm and network provides the same output under an aligned interchange intervention.**\n",
    "\n",
    "Below, we define an alignment between the neural network and the algorithm and a function to compute the **interchange intervention training accuracy** for a high-level variable, which is the percentage of aligned interchange interventions that the network and algorithm produce the same output on. When the IIT accuracy is 100%, the causal abstraction relation holds between the network and a simplified version of the algorithm where only one high-level variable exists.\n",
    "\n",
    "<img src=\"fig/IIT/alignment.png\" width=\"500\"/>\n",
    "\n",
    "We compute the IIT accuracy on our toy domain where each entity is either a pentagon, square, or triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does our alignment correspond exactly to the picture above? seems to me that the dimensions are slightly different?\n",
    "\n",
    "# we say that the first layer, which has a size of embedding_dim * 2 (in this case, 8),\n",
    "# aligns with V1 on the left and V2 on the right? (which, visually, makes sense)\n",
    "alignment = {\"V1\": {\"layer\":1, \"start\":0, \"end\":embedding_dim}, \"V2\": {\"layer\":1, \"start\":embedding_dim, \"end\":embedding_dim*2}}\n",
    "\n",
    "# performs interchange intervention on a model, given base and source inputs, and the locations\n",
    "# of where we extract the output and where we want to intervene\n",
    "def interchange_intervention(model, base, source, int_coord, output_coord):\n",
    "    # first run model on source input (start to finish), and retreive activation at the coordinate of intervention\n",
    "    intervention = model.retrieve_activations(source, int_coord[1][0],None)\n",
    "    # define our \"set\" query to be at the location of the intervention, and with the value from the base computation\n",
    "    int_coord[1][0][\"intervention\"] = intervention\n",
    "    # run the model (start to finish) on the base input with our intervention from the source input in place\n",
    "    return model.retrieve_activations(base, output_coord, int_coord)\n",
    "\n",
    "def convert_input(tensor, embedding_dim):\n",
    "    return [tuple(tensor[0,embedding_dim*k:embedding_dim*(k+1)].flatten().tolist()) for k in range(4)]\n",
    "\n",
    "def compute_IIT_accuracy(variable, model):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    # generate all possible permutations of P, T, S in 4 locations\n",
    "    # and iterate as pairs\n",
    "    for base in itertools.product([pentagon, triangle, square], repeat=4):\n",
    "        for source in itertools.product([pentagon, triangle, square], repeat=4):\n",
    "            basetensor = torch.cat([torch.tensor([base[k]]) for k in range(4)], 1)\n",
    "            sourcetensor = torch.cat([torch.tensor([source[k]]) for k in range(4)],1)\n",
    "            algorithm_output = compute_interchange_A(convert_input(basetensor, embedding_dim), convert_input(sourcetensor, embedding_dim), variable)\n",
    "            if algorithm_output[\"output\"]:   \n",
    "                labels.append(TRUE_LABEL)\n",
    "            else:\n",
    "                labels.append(FALSE_LABEL)\n",
    "            # our output comes from both activation values in the 3rd layer (how do we evaluate this as a T/F?)\n",
    "            output_coord = {\"layer\":3, \"start\":0, \"end\":2}\n",
    "            network_output = interchange_intervention(model, basetensor, sourcetensor,{1:[copy.deepcopy(alignment[variable])]}, output_coord).argmax(axis=1)\n",
    "            predictions.append(int(network_output))\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that we have low IIT accuracy for both **V1** and **V2**, meaning that under this alignment the neural network does not compute either variable. We have no evidence that this network computes simple equality relations to solve this hierarchical equality task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.29      0.36      2916\n",
      "           1       0.57      0.75      0.65      3645\n",
      "\n",
      "    accuracy                           0.55      6561\n",
      "   macro avg       0.53      0.52      0.50      6561\n",
      "weighted avg       0.53      0.55      0.52      6561\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.28      0.37      2916\n",
      "           1       0.58      0.80      0.67      3645\n",
      "\n",
      "    accuracy                           0.57      6561\n",
      "   macro avg       0.55      0.54      0.52      6561\n",
      "weighted avg       0.56      0.57      0.54      6561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in IIT, do we care both about the original accuracy and the IIT accuracy, or the IIT accuracy alone?\n",
    "# is it fair to interpret IIT accuracy as the extent to which our model is a causal abstraction of the causal\n",
    "# graph we using to compute IIT accuracy?\n",
    "\n",
    "print(classification_report(*compute_IIT_accuracy(\"V1\", model)))\n",
    "print(classification_report(*compute_IIT_accuracy(\"V2\", model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interchange Intervention Training (IIT)\n",
    "\n",
    "Original IIT [Geiger\\*, Wu\\*, Lu\\*, Rozner, Kreiss, Icard, Goodman, and Potts (2021)](https://arxiv.org/abs/2112.00826)\n",
    "\n",
    "IIT for model distillation [ Wu\\*,Geiger\\*, Rozner, Kreiss, Lu, Icard, Goodman, and Potts (2021)](https://arxiv.org/abs/2112.02505)\n",
    "\n",
    "Interchange intervention training is a method for training a neural network to conform to the causal structure of a high-level algorithm. Conceptually, it is a direct extension of the causal abstraction analysis we just performed, except instead of **evaluating** whether the neural network and algorithm produce the same outputs under aligned interchange interventions, we are now **training** the neural network to produce the output of the algorithm under aligned interchange interventions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 652. Training loss did not improve more than tol=1e-05. Final error is 0.0011470201934571378."
     ]
    }
   ],
   "source": [
    "V1 = 0\n",
    "V2 = 1\n",
    "both = 2\n",
    "# similar to our alignment in the IIT accuracy section?\n",
    "# aligning V1 to left side of layer 1, and V2 to the right side\n",
    "# we are defining both as a list with two values -- why not encode it as a single range from 0  to dim * 2?\n",
    "id_to_coords = {V1:{1: [{\"layer\":1, \"start\":0, \"end\":embedding_dim}]}, \\\n",
    "    V2: {1: [{\"layer\":1, \"start\":embedding_dim, \"end\":embedding_dim*2}]}, \\\n",
    "    both: {1: [{\"layer\":1, \"start\":0, \"end\":embedding_dim},{\"layer\":1, \"start\":embedding_dim, \"end\":embedding_dim*2}]}}\n",
    "\n",
    "# gives back an IIT dataset based off of the Premack dataset, coming up with \n",
    "# all possible permutations of same/different shape pairs and same/different base-source pairs?\n",
    "X_base_train, X_sources_train, y_base_train, y_IIT_train, interventions = get_IIT_equality_dataset(\"V1\", embedding_dim ,data_size)\n",
    "\n",
    "# this is a different model from the one we defined in the previous cell, but with a similar idea?\n",
    "model = TorchDeepNeuralClassifierIIT(hidden_dim=embedding_dim*4, hidden_activation=torch.nn.ReLU(), num_layers=3, id_to_coords=id_to_coords)\n",
    "# model.fit() function internally calls on model.create_dataset(), which creates dataset in a way that pairs off\n",
    "# source and base inputs?\n",
    "_ = model.fit(X_base_train, X_sources_train, y_base_train, y_IIT_train, interventions)\n",
    "\n",
    "# this is a runtime error I've also encountered in antra (with no change to the original code)\n",
    "# could this be due to mismatching pytorch versions??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5120\n",
      "           1       1.00      1.00      1.00      5120\n",
      "\n",
      "    accuracy                           1.00     10240\n",
      "   macro avg       1.00      1.00      1.00     10240\n",
      "weighted avg       1.00      1.00      1.00     10240\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5120\n",
      "           1       1.00      1.00      1.00      5120\n",
      "\n",
      "    accuracy                           1.00     10240\n",
      "   macro avg       1.00      1.00      1.00     10240\n",
      "weighted avg       1.00      1.00      1.00     10240\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.74      0.66      5120\n",
      "           1       0.65      0.49      0.56      5120\n",
      "\n",
      "    accuracy                           0.62     10240\n",
      "   macro avg       0.62      0.62      0.61     10240\n",
      "weighted avg       0.62      0.62      0.61     10240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_base_test, X_sources_test, y_base_test, y_IIT_test, interventions = get_IIT_equality_dataset(\"V1\", embedding_dim,data_size)\n",
    "\n",
    "IIT_preds, base_preds = model.model(model.prep_input(X_base_test, X_sources_test, interventions))\n",
    "IIT_preds = np.array(IIT_preds.argmax(axis=1).cpu())\n",
    "base_preds1 = np.array(base_preds.argmax(axis=1).cpu())\n",
    "print(classification_report(y_base_test, base_preds1))\n",
    "print(classification_report(y_IIT_test, IIT_preds))\n",
    "\n",
    "\n",
    "X_base_test, X_sources_test, y_base_test, y_IIT_test, interventions = get_IIT_equality_dataset(\"V2\", embedding_dim,data_size)\n",
    "IIT_preds, base_preds = model.model(model.prep_input(X_base_test, X_sources_test, interventions))\n",
    "IIT_preds = np.array(IIT_preds.argmax(axis=1).cpu())\n",
    "base_preds2 = np.array(base_preds.argmax(axis=1).cpu())\n",
    "print(classification_report(y_IIT_test, IIT_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that we now have perfect IIT accuracy **V1** meaning that under this alignment the neural network computes whether the first pair of inputs are equal. However, we still have low IIT accuracy for **V2**, meaning that under this alignment the neural network doesn't compute whether the second pair of inputs are equal.\n",
    "\n",
    "This is expected, because we only trained the network to compute **V1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train the network to compute both **V1** and **V2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 532. Training loss did not improve more than tol=1e-05. Final error is 0.03824407953652553."
     ]
    }
   ],
   "source": [
    "model = TorchDeepNeuralClassifierIIT(hidden_dim=embedding_dim*4, hidden_activation=torch.nn.ReLU(), num_layers=3, id_to_coords=id_to_coords)\n",
    "\n",
    "\n",
    "v1data = get_IIT_equality_dataset(\"V1\", embedding_dim, data_size)\n",
    "v2data = get_IIT_equality_dataset(\"V2\", embedding_dim, data_size)\n",
    "X_base_train = torch.cat([v1data[0],v2data[0]], dim=0)\n",
    "X_sources_train = [ torch.cat([v1data[1][i],v2data[1][i]], dim=0) for i in range(len(v1data[1]))] \n",
    "y_base_train = torch.cat([v1data[2],v2data[2]])\n",
    "y_IIT_train = torch.cat([v1data[3],v2data[3]])\n",
    "interventions = torch.cat([v1data[4],v2data[4]])\n",
    "\n",
    "_ = model.fit(X_base_train, X_sources_train, y_base_train, y_IIT_train, interventions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5120\n",
      "           1       1.00      1.00      1.00      5120\n",
      "\n",
      "    accuracy                           1.00     10240\n",
      "   macro avg       1.00      1.00      1.00     10240\n",
      "weighted avg       1.00      1.00      1.00     10240\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5120\n",
      "           1       1.00      1.00      1.00      5120\n",
      "\n",
      "    accuracy                           1.00     10240\n",
      "   macro avg       1.00      1.00      1.00     10240\n",
      "weighted avg       1.00      1.00      1.00     10240\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5120\n",
      "           1       1.00      1.00      1.00      5120\n",
      "\n",
      "    accuracy                           1.00     10240\n",
      "   macro avg       1.00      1.00      1.00     10240\n",
      "weighted avg       1.00      1.00      1.00     10240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_base_test, X_sources_test, y_base_test, y_IIT_test, interventions = get_IIT_equality_dataset(\"V1\", embedding_dim,data_size)\n",
    "\n",
    "# training it once for causally abstracting V1\n",
    "IIT_preds, base_preds = model.model(model.prep_input(X_base_test, X_sources_test, interventions))\n",
    "IIT_preds = np.array(IIT_preds.argmax(axis=1).cpu())\n",
    "base_preds = np.array(base_preds.argmax(axis=1).cpu())\n",
    "print(classification_report(y_base_test, base_preds))\n",
    "print(classification_report(y_IIT_test, IIT_preds))\n",
    "\n",
    "# training it again for causally abstracting V2\n",
    "X_base_test, X_sources_test, y_base_test, y_IIT_test, interventions = get_IIT_equality_dataset(\"V2\", embedding_dim,data_size)\n",
    "IIT_preds, base_preds = model.model(model.prep_input(X_base_test, X_sources_test, interventions))\n",
    "IIT_preds = np.array(IIT_preds.argmax(axis=1).cpu())\n",
    "base_preds = np.array(base_preds.argmax(axis=1).cpu())\n",
    "print(classification_report(y_IIT_test, IIT_preds))\n",
    "\n",
    "# seems that training one after the other doesn't \"undo\" previous learning - will this always be the case?\n",
    "# does order matter, or is there anything we should watch out for here?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2916\n",
      "           1       1.00      1.00      1.00      3645\n",
      "\n",
      "    accuracy                           1.00      6561\n",
      "   macro avg       1.00      1.00      1.00      6561\n",
      "weighted avg       1.00      1.00      1.00      6561\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2916\n",
      "           1       1.00      1.00      1.00      3645\n",
      "\n",
      "    accuracy                           1.00      6561\n",
      "   macro avg       1.00      1.00      1.00      6561\n",
      "weighted avg       1.00      1.00      1.00      6561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(*compute_IIT_accuracy(\"V1\", model.model)))\n",
    "print(classification_report(*compute_IIT_accuracy(\"V2\", model.model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multisource IIT\n",
    "\n",
    "We can also extend IIT to a setting where a base input has several source inputs. Consider an intervention to the high-level algorithm that fixes both intermediate variables. We can perform an interchange intervention on the neural network where the neurons aligned with the left intermediate variable have one source input and the neurons aligned with the right intermediate variable have a second source input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this time, intervening on V1 and V2 at the same time? but from two different sources (so we can still generate all\n",
    "# possible pairs)\n",
    "def compute_multisource_interchange_A(base,source,source2):\n",
    "    return compute_A(base, {\"V1\":compute_A(source, {})[\"V1\"], \"V2\":compute_A(source2, {})[\"V2\"]})\n",
    "\n",
    "def multisource_interchange_intervention(model, base, sources, coords, output_coord):\n",
    "    source_activations = model.retrieve_activations(sources[0], coords[1][0],None)\n",
    "    source_activations2 = model.retrieve_activations(sources[1], coords[1][1],None)\n",
    "    coords = copy.deepcopy(coords)\n",
    "    coords[1][0][\"intervention\"] = source_activations\n",
    "    coords[1][1][\"intervention\"] = source_activations2\n",
    "    return model.retrieve_activations(base, output_coord, coords)\n",
    "\n",
    "def compute_multisource_IIT_accuracy(model, coords):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    # iterate through all possible bases, and then through all possible V1 and V2 intervention values\n",
    "    # seems a bit inefficient -- how does this approach compare to many single sources? where might this approach be better?\n",
    "    for base in itertools.product([pentagon, triangle, square], repeat=4):\n",
    "        for source in itertools.product([pentagon, triangle, square], repeat=4):\n",
    "            for source2 in itertools.product([pentagon, triangle, square], repeat=4):\n",
    "                basetensor = torch.cat([torch.tensor([base[k]]) for k in range(4)], 1)\n",
    "                sourcetensor = torch.cat([torch.tensor([source[k]]) for k in range(4)],1)\n",
    "                sourcetensor2 = torch.cat([torch.tensor([source2[k]]) for k in range(4)],1)\n",
    "                algorithm_output = compute_multisource_interchange_A(convert_input(basetensor, embedding_dim), convert_input(sourcetensor, embedding_dim),convert_input(sourcetensor2, embedding_dim))\n",
    "                if algorithm_output[\"output\"]:   \n",
    "                    labels.append(TRUE_LABEL)\n",
    "                else:\n",
    "                    labels.append(FALSE_LABEL)\n",
    "                get_coord = {\"layer\":3, \"start\":0, \"end\":2}\n",
    "                network_output = multisource_interchange_intervention(model, basetensor, [sourcetensor,sourcetensor2], coords, get_coord).argmax(axis=1)\n",
    "                predictions.append(int(network_output))\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    236196\n",
      "           1       1.00      0.99      1.00    295245\n",
      "\n",
      "    accuracy                           0.99    531441\n",
      "   macro avg       0.99      1.00      0.99    531441\n",
      "weighted avg       0.99      0.99      0.99    531441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# seems that model already does well for multisource IIT accuracy - will this generally be the case?\n",
    "# how would you recommend choosing which nodes from the graph to train our model against?\n",
    "sets = {1: [{\"layer\":1, \"start\":0, \"end\":embedding_dim},{\"layer\":1, \"start\":embedding_dim, \"end\":embedding_dim*2}]}\n",
    "print(classification_report(*compute_multisource_IIT_accuracy(model.model, sets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 610. Training loss did not improve more than tol=1e-05. Final error is 0.14826767449267209."
     ]
    }
   ],
   "source": [
    "v1data = get_IIT_equality_dataset(\"V1\", embedding_dim ,data_size)\n",
    "v2data = get_IIT_equality_dataset(\"V2\", embedding_dim ,data_size)\n",
    "bothdata = get_IIT_equality_dataset_both(embedding_dim ,data_size)\n",
    "# are we training the model to become a causal abstraction for V1, V2, and both all at once?\n",
    "# could we have done the same when considering V1 and V2?\n",
    "X_base_train = torch.cat([v1data[0],v2data[0], bothdata[0]], dim=0)\n",
    "X_sources_train = [ torch.cat([v1data[1][0],v2data[1][0], bothdata[1][i]], dim=0) for i in range(len(bothdata[1]))] \n",
    "y_base_train = torch.cat([v1data[2],v2data[2],bothdata[2]])\n",
    "y_IIT_train = torch.cat([v1data[3],v2data[3], bothdata[3]])\n",
    "interventions = torch.cat([v1data[4],v2data[4], bothdata[4]])\n",
    "\n",
    "model = TorchDeepNeuralClassifierIIT(hidden_dim=embedding_dim*4, hidden_activation=torch.nn.ReLU(), num_layers=3, id_to_coords=id_to_coords)\n",
    "\n",
    "_ = model.fit(X_base_train, X_sources_train, y_base_train, y_IIT_train, interventions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    236196\n",
      "           1       1.00      1.00      1.00    295245\n",
      "\n",
      "    accuracy                           1.00    531441\n",
      "   macro avg       1.00      1.00      1.00    531441\n",
      "weighted avg       1.00      1.00      1.00    531441\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2916\n",
      "           1       1.00      1.00      1.00      3645\n",
      "\n",
      "    accuracy                           1.00      6561\n",
      "   macro avg       1.00      1.00      1.00      6561\n",
      "weighted avg       1.00      1.00      1.00      6561\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2916\n",
      "           1       1.00      1.00      1.00      3645\n",
      "\n",
      "    accuracy                           1.00      6561\n",
      "   macro avg       1.00      1.00      1.00      6561\n",
      "weighted avg       1.00      1.00      1.00      6561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(*compute_multisource_IIT_accuracy(model.model, sets)))\n",
    "print(classification_report(*compute_IIT_accuracy(\"V1\", model.model)))\n",
    "print(classification_report(*compute_IIT_accuracy(\"V2\", model.model)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "933b0a94e0d88ac80a17cb26ca3d8d36930c12815b02a2885c1925c2b1ae3c33"
  },
  "kernelspec": {
   "display_name": "iit",
   "language": "python",
   "name": "iit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
